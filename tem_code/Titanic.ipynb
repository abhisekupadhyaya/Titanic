{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support as prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The features of the datasets will be the coloum name in data table. \n",
    "#'col_name' cointains the names of the features of the dataset of training data\n",
    "#'test_col' cointains the names of the feature in test dataset\n",
    "#'expected_col' cointains the name of the features that are to be predicted from 'test_col', here 'survival'\n",
    "\n",
    "col_name = ['id', 'survival', 'p_class', 'name', 'sex', 'age', 'sib_sp', 'par_ch', 'ticket_no', 'fare', 'cabin_no', 'embarked']\n",
    "test_col = ['id', 'p_class', 'name', 'sex', 'age', 'sib_sp', 'par_ch', 'ticket_no', 'fare', 'cabin_no', 'embarked']\n",
    "expected_col =['id', 'survival']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The file 'test.csv' cointains the data that should be used to train the hypothesis.\n",
    "#'test.csv' cointains the data on which the hypothesis is to be tested. \n",
    "#The expected prediction, ie. 'survival', on dataset 'test.csv' is given in 'gender_submission.csv'\n",
    "\n",
    "train_df = pd.read_csv('../Data/train.csv', delimiter = ',', names = col_name, quotechar='\"', skiprows = [0])\n",
    "test_df = pd.read_csv('../Data/test.csv', delimiter = ',', names = test_col, quotechar='\"', skiprows = [0])\n",
    "expected_df = pd.read_csv('../Data/gender_submission.csv', delimiter = ',', names = expected_col, skiprows = [0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The train(train_df) dataset is divided into two parts\n",
    "#The first part(train_outcome) cointains the values of the features that hypothesis should predict\n",
    "#The secound part(train_data) cointains the values of the features on the basis of which hypothesis predicts.\n",
    "#Simillary the required features of the test dataset are extracted where data wh=ith age is 'NaN' is ignored\n",
    "#From Dummies variable we get two coloum, one which shows 1 if 'male' other coloum shows 1 if 'female'.\n",
    "#We choose the former. This is done because logistic regression classifies can only optimize numerical inputs.\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "train_data['p_class'] = train_df['p_class']\n",
    "train_data['age'] = train_df['age']\n",
    "train_data['sex'] = pd.get_dummies(train_df['sex'])['male']\n",
    "train_outcome = train_df[ 'survival']\n",
    "\n",
    "test_data['p_class'] = test_df['p_class']\n",
    "test_data['age'] = test_df['age']\n",
    "test_data['sex'] = pd.get_dummies(test_df['sex'])['male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#There are data in testset which does not have age.\n",
    "#For these datas, the age is assumed to be the median of age with same 'p_class' and 'sex'\n",
    "\n",
    "for data_sex in [0 , 1]:\n",
    "    #Sub-dataset with particular 'sex' is made\n",
    "    train_data_gender = train_data[train_data['sex'] == data_sex]\n",
    "    test_data_gender = test_data[test_data['sex'] == data_sex]\n",
    "    for data_class in [1, 2 , 3]:\n",
    "        #Sub-dataset with particular 'sex' and 'p_class' is made\n",
    "        train_data_class = train_data_gender[train_data_gender['p_class'] == data_class]\n",
    "        test_data_class = test_data_gender[test_data_gender['p_class'] == data_class].copy()\n",
    "        \n",
    "        #Median of age with the particular 'p_class' and 'sex' is computed\n",
    "        missing_age = np.int(np.median(train_data_class['age']))\n",
    "        \n",
    "        #The data with missing 'age' is replaced with the computed age\n",
    "        test_data_class['age'] = test_data_class['age'].fillna(missing_age)\n",
    "        test_data[(test_data['sex'] == data_sex) & (test_data_gender['p_class'] == data_class)] = test_data_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The Feature are scaled inorder to avoid dominance of a type of data over others while training the logistic regression\n",
    "#Here MinMaxScalar is used, which converts x to (x - xmin)/(xmax - xmin), where xmin and xmax are of training set\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_data)\n",
    "\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The data is being trained with various values of Regularization Strength and number of iteration.\n",
    "#The Precision, Recall and F values for all the combination is stored in 'data_outcome'\n",
    "\n",
    "##quality_features = ['C', 'Iteration', 'Precision', 'Recall', 'F1']\n",
    "##hypothesis_quality = pd.DataFrame(data = None, columns = quality_features, dtype = float)\n",
    "##\n",
    "##predicted_df = pd.DataFrame(data = expected_df['id'])\n",
    "##\n",
    "##for c in [0.01, 0.3, 1.0 , 3.0, 10.0]:\n",
    "##    for max_it in [100, 500, 1000, 2000]:\n",
    "##        #The hypothesis was chosen and trained\n",
    "##        hypothesis = LogisticRegression(C=c, max_iter = max_it, solver='lbfgs') \n",
    "##        hypothesis.fit(train_data, train_outcome)\n",
    "##        \n",
    "##        #The hypothesis was used to predicted and  values are stored in \"predicted_df['survival']\"\n",
    "##        predicted_Series = pd.Series(data = hypothesis.predict(test_data), dtype = bool)\n",
    "##        predicted_df['survival'] = predicted_Series\n",
    "##        \n",
    "##        #Precision, Recall, and F_Scores are computed and stored in 'hypothesis_quality'\n",
    "##        #Along with the above values their Regularization Strength and number of iteration perfored is stored.\n",
    "##        True_Positive = sum((expected_df['survival'] == 1) & (predicted_df['survival'] == 1))\n",
    "##        False_Positive = sum((expected_df['survival'] == 0) & (predicted_df['survival'] == 1))\n",
    "##        False_Negative = sum((expected_df['survival'] == 0) & (predicted_df['survival'] == 0))\n",
    "##        \n",
    "##        precision = True_Positive / (True_Positive + False_Positive)\n",
    "##        recall = True_Positive / (True_Positive + False_Negative)\n",
    "##        F_Score = (precision * (recall*2.0))/(recall + precision)\n",
    "##        \n",
    "##        hypothesis_quality.loc[hypothesis_quality.size/5] = [c, max_it , precision, recall, F_Score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The optimum value found for Regularization Strength is 1 and for number of iteration is 100.\n",
    "#So the hypothesis is trained.\n",
    "hypothesis = LogisticRegression(solver='lbfgs') \n",
    "hypothesis.fit(train_data, train_outcome)\n",
    "\n",
    "#The values are used on test dataset to predict the survival of people\n",
    "predicted_df = pd.DataFrame(data = expected_df['id'])\n",
    "predicted_Series = pd.Series(data = hypothesis.predict(test_data), dtype = bool)\n",
    "predicted_df['survival'] = predicted_Series\n",
    "\n",
    "#The acuracy rate is competed against athe hypothesis where everyone is assumed to be dead\n",
    "#The 'defult_accuracy' is the acurracy of the hypothesis which predicts everyone to be dead\n",
    "#The 'predicted_accuracy' is he acurracy of the hypothesis which is trained using logistic regression.\n",
    "no_of_prediction, no_of_features = predicted_df.shape\n",
    "\n",
    "defult_accuracy = 1 - (sum(expected_df['survival'])/no_of_prediction)\n",
    "predicted_accuracy = sum((predicted_df['survival'] == expected_df['survival']))/no_of_prediction"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
